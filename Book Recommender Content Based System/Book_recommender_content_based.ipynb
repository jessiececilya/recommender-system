{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Book recommender content based",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPqYyq4ZLx6lvwextiGQo2h",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jessiececilya/Projects/blob/main/Book_recommender_content_based.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jy0PNEbjUWXW"
      },
      "source": [
        "import pandas as pd\n",
        "from rake_nltk import Rake\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import re\n",
        "import string\n",
        "pd.set_option('display.max_colwidth',100)\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from langdetect import detect\n",
        "stopwords = nltk.corpus.stopwords.words('english')\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EN41vRlTUbzJ"
      },
      "source": [
        "#pip install rake_nltk\n",
        "#pip install langdetect\n"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LScHKNv_--kl"
      },
      "source": [
        "#Read data\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/jessiececilya/ML-Data/main/book_data.csv')\n"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1f25604OQGZ"
      },
      "source": [
        "#Taking 2000 samples to limit to the capacity\n",
        "df= df.iloc[0:2000,:]\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YqzJxfnxXcXZ"
      },
      "source": [
        "#convert author names from \"Harper Lee\" to \"harperlee\"\n",
        "def joinnames(text):\n",
        "  l= ''.join(re.split(\" \",text.lower()))\n",
        "  return l\n",
        "\n",
        "df['book_authors']= df['book_authors'].apply (lambda x: joinnames(x))"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J08-HWH4U3Ai"
      },
      "source": [
        "#Replace separators '|' by space\n",
        "def to_string(x):\n",
        "    if x:\n",
        "        return str(x).replace('|',' ')\n",
        "    else:\n",
        "        return ''\n",
        "\n",
        "df['book_authors']= df['book_authors']. apply(lambda x: to_string(x))\n",
        "df['genres']= df['genres'].apply(lambda x: to_string(x))\n",
        "\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z9vJoKZYXncu"
      },
      "source": [
        "#convert to lowercase\n",
        "df['genres']= df['genres'].apply(lambda x: x.lower())\n",
        "df['book_title']= df['book_title'].apply(lambda x: x.lower())\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Mcx0lLEdSUq"
      },
      "source": [
        "#identify the language function\n",
        "def lang(text):\n",
        "  try:\n",
        "    return detect(text)\n",
        "  except:\n",
        "    return 'error' \n",
        "\n",
        "df['book_desc']= df['book_desc'].astype(str)\n",
        "df['lang']= df['book_desc'].apply(lambda x: lang(x))"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_vo-KH9bF55"
      },
      "source": [
        "#keep only english language description\n",
        "df= df[df['lang']=='en']\n",
        "df=df.reset_index(drop=True)\n"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2imiH4umnnc"
      },
      "source": [
        "#clean the book description to perform futher keyword analysis\n",
        "def clean_text(text):\n",
        "    text = \"\".join([word for word in text if word not in string.punctuation])\n",
        "    tokens = re.split('\\W+', text)\n",
        "    text = [word for word in tokens if word not in stopwords]\n",
        "    return text\n",
        "df['book_desc']= df['book_desc'].apply(lambda x: clean_text(x.lower()))\n",
        "df['book_desc']= df['book_desc'].apply(lambda x: ' '.join(x))\n"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2T2TxtOXs6bi"
      },
      "source": [
        "#Keeping desc in a separate variable to not disrupt the cleaned df data\n",
        "j= pd.DataFrame(df, columns=['book_desc']).astype(str)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSgHV3AvcRjY"
      },
      "source": [
        "#function to identify keywords using Rake\n",
        "j['Key_words'] = \"\"\n",
        "\n",
        "for index, row in j.iterrows():\n",
        "    desc = row['book_desc']\n",
        "        \n",
        "    # instantiating Rake, by default it uses english stopwords from NLTK\n",
        "    # and discards all puntuation characters as well\n",
        "    r = Rake()\n",
        "\n",
        "    # extracting the words by passing the text\n",
        "    r.extract_keywords_from_text(desc)\n",
        "\n",
        "    # getting the dictionary whith key words as keys and their scores as values\n",
        "    key_words_dict_scores = r.get_word_degrees()\n",
        "    \n",
        "    # assigning the key words to the new column for the corresponding movie\n",
        "    row['Key_words'] = list(key_words_dict_scores.keys())\n",
        "\n",
        "\n"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KVHsyIQbkbxF"
      },
      "source": [
        "#Combine j keywords into df\n",
        "df['Keywords']= j['Key_words']"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTAiULhc0d9T"
      },
      "source": [
        "#Create a bag of words using all content based attributes\n",
        "df['bag_of_words']= df['book_authors'].astype(str) +' ' + df['book_title'].astype(str) +' '+ df['Keywords'].astype(str)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2TftofbE0-Be"
      },
      "source": [
        "#drop duplicates based on book title columns\n",
        "x= df.drop_duplicates(subset=['book_title'], keep= 'first')\n",
        "x=x.reset_index(drop=True)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MbGqTx9f1iFZ"
      },
      "source": [
        "# instantiating and generating the count matrix\n",
        "count = CountVectorizer()\n",
        "count_matrix = count.fit_transform(x['bag_of_words'])\n",
        "\n",
        "# generating the cosine similarity matrix\n",
        "cosine_sim = cosine_similarity(count_matrix, count_matrix)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RX5LXWlv1n9l"
      },
      "source": [
        "# creating a Series for the movie titles so they are associated to an ordered numerical\n",
        "# list I will use in the function to match the indexes\n",
        "indices = pd.Series(x.index)\n",
        "\n",
        "#  defining the function that takes in movie title \n",
        "# as input and returns the top 10 recommended movies\n",
        "def recommendations(title, cosine_sim = cosine_sim):\n",
        "    \n",
        "    # initializing the empty list of recommended movies\n",
        "    recommended_movies = []\n",
        "    \n",
        "    # gettin the index of the movie that matches the title\n",
        "    idx = indices[indices == title].index[0]\n",
        "\n",
        "    # creating a Series with the similarity scores in descending order\n",
        "    score_series = pd.Series(cosine_sim[idx]).sort_values(ascending = False)\n",
        "\n",
        "    # getting the indexes of the 10 most similar movies\n",
        "    top_10_indexes = list(score_series.iloc[1:11].index)\n",
        "    \n",
        "    # populating the list with the titles of the best 10 matching movies\n",
        "    for i in top_10_indexes:\n",
        "        recommended_movies.append(list(x.index)[i])\n",
        "        \n",
        "    return recommended_movies"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwB1tFkA2kfM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ffe92f00-4723-4219-9d83-a6faf875cd6b"
      },
      "source": [
        "#recommendation list\n",
        "title= \"the hunger games\"\n",
        "j=recommendations(df[df['book_title']==title].index[0], cosine_sim)\n",
        "for i in j:\n",
        "  print(df.iloc[i]['book_title'])"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the girl who played with fire\n",
            "throne of glass\n",
            "absalom, absalom!\n",
            "a child called \"it\"\n",
            "kiss the girls\n",
            "cat's cradle\n",
            "bloodlines\n",
            "kafka on the shore\n",
            "the mill on the floss\n",
            "peter pan\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZTcXvHvPrE5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}